# 提示词体系演进构想：从“静态模板”到“智能生成”

**创建日期**: 2025-11-26
**背景**: 基于用户对 `prompts-library` 扩展（虚拟研发团队）的实践与思考。

---

## 1. 核心愿景

将当前的“静态提示词模板库”升级为一套**“动态的、可自我进化的提示词元数据管理体系”**。最终目标是实现**工作自动化**，即通过智能预测生成“一步到位”的可执行提示词，并驱动 Agent 系统完成交付。

## 2. 演进阶段规划

### 阶段一：分层提示词架构 (Layered Prompt Architecture)
**现状**: 目前的提示词混合了能力描述和部分规则。
**未来**: 明确区分“基座”与“扩展”。
*   **基座层 (Base Layer - 母版)**: 定义角色最底层的、通用的核心能力（如：“你是一个精通 Python 的数据分析师，擅长...”）。这部分存储在母版中。
*   **应用层 (App Layer - 项目级)**: 定义符合特定项目上下文的“追加描述”（如：“本项目是关于电商库存预测的，需使用 Prophet 模型...”）。
*   **关系**: `最终执行提示词 = 基座层 + 应用层`。

### 阶段二：知识回流与元数据积累 (Knowledge Harvesting)
建立从“具体项目”反哺“母版知识库”的机制。
1.  **提取 (Extract)**: 项目结束后，分析其实际使用的提示词。
2.  **差分 (Diff)**: 剥离掉“基座层”，提取出该项目中特有的“应用层增量”。
3.  **沉淀 (Deposit)**: 将这些增量标记为特定领域的元数据（Domain Metadata）。
    *   *例如*: 从一个爬虫项目中提取出关于“反爬策略处理”的专用描述，存入“爬虫领域知识库”。

### 阶段三：预测性提示词生成 (Predictive Prompt Generation)
利用积累的元数据，实现从“手动填空”到“智能预测”的跨越。
*   **输入**: 用户仅需输入模糊的项目意图（如：“我想做一个爬取股票数据的 Streamlit 工具”）。
*   **预测**: 系统检索知识库，自动匹配：
    *   需要哪些角色？（产品经理 + 爬虫工程师 + Streamlit 开发者）
    *   每个角色需要追加什么具体的领域知识？（自动挂载“金融数据清洗规则”和“Streamlit 股票图表组件库”）。
*   **输出**: 自动生成一套可以直接执行的、包含丰富细节的项目级提示词。

### 阶段四：多 Agent 协同自动化 (Agent Orchestration)
*   **虚拟团队**: 建立 Agent 系统，能够解析上述生成的复杂提示词。
*   **自动实例化**: 系统自动根据定义好的角色创建对应的 Agent 实例。
*   **闭环工作**: Agent 之间根据预设的工作流（Workflow）进行交互，完成从需求到代码的交付。

## 3. 关键动作 (Next Steps)
*   [ ] **标准化结构**: 在 `prompts-library` 中尝试拆分“能力描述”与“项目约束”。
*   [ ] **元数据定义**: 思考如何以结构化数据（如 JSON/YAML）来描述提示词的元数据，而不仅仅是 Markdown 文本。
*   [ ] **试点项目**: 利用“虚拟研发团队”作为试点，手动模拟一次“提取增量”的过程，看看能沉淀出什么通用知识。

---

## 4. 深度架构讨论 (Deep Dive Discussion)

### Q1: 提示词结构：追加式 vs 嵌入式？
**问题**: 明确区分“基座”和“追加内容”（如使用特定标记）是否会影响 LLM 效果？是否应强制“只能在尾部追加”？
**策略**:
1.  **上下文隔离 (Context Isolation)**: 单纯的尾部追加虽然简单，但容易导致“指令遗忘”或“权重被覆盖”。更好的方式是使用 **XML 标签**（如 `<project_context>...</project_context>`）或 **Markdown 显式分节**（`## 项目特定约束`）。
2.  **结构化优势**: 这种显式的结构化不仅不会降低 LLM 效果，反而能帮助 LLM 更好地区分“通用规则”和“特定数据”，减少幻觉。
3.  **结论**: 推荐采用“插槽式”或“显式分节”结构，而非简单的文本追加。这有利于未来的程序化提取。

### Q2: 归档机制：脚本 vs 大模型？
**问题**: 如何提取和存储海量的项目元数据？脚本机械化提取是否可靠？
**策略**:
1.  **LLM 为脑，脚本为手**: 纯脚本无法理解语义（例如区分哪些是核心逻辑，哪些是业务细节），纯 LLM 无法高效操作文件系统。
2.  **归档流程**:
    *   **第一步 (IO)**: 脚本遍历项目文档。
    *   **第二步 (Thinking)**: 调用“图书管理员 Agent” (Librarian Agent)，对比“母版提示词”和“项目最终提示词”，智能提取 Diff（增量）。
    *   **第三步 (Storage)**: 脚本将 Agent 输出的结构化数据（JSON/YAML）存入知识库。
3.  **结论**: 必须建立 **Agent-Led Pipeline**。归档不仅是复制，更是“知识蒸馏”的过程。

### Q3: 边界界定：规则 (Rules) vs 资产 (Assets)
**问题**: “元角色”（如提示词评审员、项目管理助手）应该放在 `.cursor/rules` 还是 `prompts-library`？
**原则**: **运行时上下文 (Runtime Context) vs 工具资产 (Tool Assets)**
1.  **`.cursor/rules` (宪法)**: 存放**必须**时刻生效的规则。例如：“始终使用中文”、“总是先思考再行动”。这些规则会消耗每一次对话的 Context Window。
2.  **`prompts-library` (工具箱)**: 存放**按需**调用的角色。例如：“提示词评审员”。我们不需要在写代码时让“提示词评审员”一直盯着，只有在写提示词时才需要“请”他出来。
3.  **`_meta` (工厂设施)**: 存放维护模板本身所需的工具。
**结论**:
    *   如果“元角色”是用来辅助用户生成新项目的，它属于 `prompts-library/ops`（运维类角色）。
    *   如果“元角色”是用来约束当前 AI 行为的，它属于 `.cursor/rules`。
    *   绝大多数具体的“元角色”（如 Critic, Generator）应放在 **`prompts-library`** 中，按需加载，避免污染日常开发上下文。

---
*本文档由 AI 助理根据用户构想整理记录，作为项目长期演进的战略参考。*
